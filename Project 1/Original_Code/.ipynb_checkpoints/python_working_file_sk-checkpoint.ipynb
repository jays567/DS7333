{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study 1: MSDS 7333 Spring 2020\n",
    "\n",
    "***Sean Kennedy***\n",
    "\n",
    "***Sterling Beason***\n",
    "\n",
    "***Emil Ramos***\n",
    "\n",
    "*Souther Methodist University*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Knowing the location of business-critical machiney and/or workers is essential to optimize productivity for organizations that live and die by shipping times, workflow prioritization, deliverable timelines, and cost minimization. Real-time location systems (RTLS) have enabled some business to be in a position to monitor their assets through the production cycle. \n",
    "\n",
    "In this case study, we are evaluating the use of RTLS over wifi for an organization. Specifically, our authors (Nolan and Lang) posit that by distributing various wifi-enabled RTLS devices across the facility to assets, one might be able to use clustering methods to ascertain the predicted position of those assets based on past behavior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective: Using the OFFLINE data and two different clustering methods predict the location of the ONLINE data set.  \n",
    "\n",
    "Our two methods will be:\n",
    "\n",
    "- weighted kNN\n",
    "\n",
    "- unweighted kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import floor\n",
    "from random import sample\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Determines which macIds to include in analysis. Not all macs have enough readings to be observed. The following list meets the minimum threhold established in the EDA section. It will be updated later in the analysis to consider a different group of macs in the creation of our kNN graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "macs_to_keep = ['00:0f:a3:39:e1:c0',    \n",
    "            '00:0f:a3:39:dd:cd', \n",
    "            '00:14:bf:b1:97:8a',\n",
    "            '00:14:bf:3b:c7:c6',    \n",
    "            '00:14:bf:b1:97:90',  \n",
    "            '00:14:bf:b1:97:8d',\n",
    "            '00:14:bf:b1:97:81',\n",
    "            '02:00:42:55:31:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code/Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Dictionary\n",
    "\n",
    "The columns from the raw OFFLINE dataset\n",
    "\n",
    "| Variable | Description |\n",
    "| - | - |\n",
    "| t | timestamp (ms) of scan |\n",
    "| id | MAC address of scanning device |\n",
    "| pos | comma separated position (x, y, z) |\n",
    "| degree | orientation of scanning device |\n",
    "| (mac)* | MAC address(es) of access points as key with comma separated value (signal, channel, type) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(sample_data, test_data, ks, m, macs=macs_to_keep):\n",
    "    online = test_data.copy().reset_index()\n",
    "    all_predictions = []\n",
    "    for k in ks:\n",
    "        #print(k)\n",
    "        predictions = []\n",
    "        for index, sample_row in online.iterrows():\n",
    "            sample = get_train_data_by_angle(data=sample_data\n",
    "                                             , ref_angle=sample_row['dummy_angle']\n",
    "                                             , angles=m)\n",
    "            sample = calc_distance(sample, sample_row, macs=macs)\n",
    "            sample = sample.reset_index()\n",
    "            #k sets nearest neighbors used for predictions\n",
    "            p = predict(sample, k=k, weight=True)\n",
    "            p.update({\n",
    "                'k': k,\n",
    "                'target_x': float(sample_row['xy-loc'].split('-')[0]),\n",
    "                'target_y': float(sample_row['xy-loc'].split('-')[1])\n",
    "            })\n",
    "            predictions.append(\n",
    "                p\n",
    "            )\n",
    "        all_predictions += predictions\n",
    "        \n",
    "            \n",
    "    return pd.DataFrame(all_predictions)\n",
    "\n",
    "def score(predictions):\n",
    "    #apply error function described below\n",
    "    predictions = predictions.copy()\n",
    "    predictions['error'] = [((row['target_x'] - row['pred_x'])**2+((row['target_y'] - row['pred_y'])**2))**.5 for x, row in predictions.iterrows()]\n",
    "    predictions['error_weighted'] = [((row['target_x'] - row['pred_x_weighted'])**2+((row['target_y'] - row['pred_y_weighted'])**2))**.5 for x, row in predictions.iterrows()]\n",
    "    return predictions\n",
    "\n",
    "def round_angle(angle):\n",
    "    #rounds angle to integer values (of 45 ny default)\n",
    "    buckets = [angle for angle in angle_buckets()]\n",
    "    angle = angle if angle < 360 else angle-360\n",
    "    angles = [abs(a - angle) for a in buckets]\n",
    "    sorted_angles = angles.copy()\n",
    "    sorted_angles.sort()\n",
    "    min_val = sorted_angles[0]\n",
    "    min_index = angles.index(min_val)\n",
    "    return buckets[min_index]\n",
    "    \n",
    "\n",
    "def angle_buckets(start = 0, end = 360, step = 45):\n",
    "     for i in range(0, int(round(end/step, 0)) + 1):\n",
    "            val = start + i*step\n",
    "            yield val\n",
    "\n",
    "angles = [a for a in angle_buckets()]\n",
    "\n",
    "def get_train_data_by_angle(data, ref_angle=225, angles=3):\n",
    "    ref_angle = round_angle(ref_angle)\n",
    "    #assert angles <= 7\n",
    "    buckets = [angle for angle in angle_buckets()]\n",
    "    if angles:\n",
    "        start_index = buckets.index(ref_angle)- int(floor(angles/2))\n",
    "        keep_angles = []\n",
    "        for x in range(start_index, start_index + angles):\n",
    "            keep_angles.append(buckets[x])\n",
    "        #print(keep_angles)\n",
    "        data = data[data['mapped_orientation'].isin(keep_angles)].copy()\n",
    "    grouped_df = data.groupby(['mac', 'xy-loc'])['signal'].agg(['mean']).reset_index()\n",
    "    grouped_df = pd.pivot_table(grouped_df, values='mean', columns='mac', index=['xy-loc'])\n",
    "    assert grouped_df.shape[0] == 166\n",
    "    return grouped_df\n",
    "\n",
    "def calc_distance(sample_data, test_row, macs=macs_to_keep):\n",
    "    differences = []\n",
    "    for index, row in sample_data.iterrows():\n",
    "        diff = sum([(row[col]-test_row[col])**2 for col in macs])**0.5\n",
    "        #test_row.loc[index, 'distance'] = diff\n",
    "        differences.append(diff)\n",
    "    sample_data['distance'] = differences\n",
    "    return sample_data.sort_values(['distance'])\n",
    "\n",
    "\n",
    "def predict(sample_data, k=3, weight=False):\n",
    "    sample_data = sample_data.head(k).copy()\n",
    "    sample_data['x'] = sample_data['xy-loc'].apply(lambda x: x.split('-')[0])\n",
    "    sample_data['y'] = sample_data['xy-loc'].apply(lambda y: y.split('-')[1])\n",
    "    sample_data['x'] = pd.to_numeric(sample_data['x'])\n",
    "    sample_data['y'] = pd.to_numeric(sample_data['y'])\n",
    "    sample_data['inverse_distance'] = 1/sample_data['distance']\n",
    "    total_inv_dist = sample_data['inverse_distance'].sum()\n",
    "    sample_data['distance_weight'] = sample_data['inverse_distance']/total_inv_dist\n",
    "    assert sample_data.shape[0] == k\n",
    "    return {\n",
    "        'pred_x':sample_data['x'].mean(),\n",
    "        'pred_y': sample_data['y'].mean(),\n",
    "        'pred_x_weighted': (sample_data['x'] * sample_data['distance_weight']).sum(),\n",
    "        'pred_y_weighted':  (sample_data['y'] * sample_data['distance_weight']).sum(),\n",
    "        'inv_dist':total_inv_dist\n",
    "    }\n",
    "\n",
    "\n",
    "f_offline = '../Data/offline.final.trace.txt'\n",
    "f_online = '../Data/online.final.trace.txt'\n",
    "\n",
    "def get_data(file_name, add_dummy=False, macs=macs_to_keep, agg=False):\n",
    "    column_names = ['time', 'scanMac', 'posX', 'posY', 'posZ', 'orientation', 'mac', 'signal', 'channel', 'type']\n",
    "    lines = None\n",
    "    with open(file_name, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        file.close()\n",
    "    instances = [] # will hold final data for dataframe\n",
    "\n",
    "    for line in lines:\n",
    "\n",
    "        # strip \"\\n\" from line\n",
    "        line = line.rstrip('\\n')\n",
    "\n",
    "        # skip if comment\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "\n",
    "        base = [] # [t, id, x, y, z, degree]\n",
    "        rows = [] # base + [mac, signal, channel, type]\n",
    "\n",
    "        for keyvalue in line.split(';'):\n",
    "            key, value = keyvalue.split('=')\n",
    "\n",
    "            if key in ['t', 'id', 'degree']:\n",
    "                base.append(value)\n",
    "            elif key == 'pos':\n",
    "                # pos (x, y, z)\n",
    "                base += value.split(',')\n",
    "            else:\n",
    "                # mac addresses and metrics (signal, channel, type)\n",
    "                row = base.copy()\n",
    "                row.append(key)\n",
    "                row += value.split(',')\n",
    "                rows.append(row)\n",
    "\n",
    "        instances += rows\n",
    "\n",
    "    df_online = pd.DataFrame(instances, columns = column_names)\n",
    "    df_online.orientation = pd.to_numeric(df_online['orientation'])\n",
    "    df_online['mapped_orientation'] = df_online['orientation'].apply(lambda x: round_angle(x))\n",
    "\n",
    "    df_online['xy-loc'] = df_online['posX'] + '-' + df_online['posY']\n",
    "\n",
    "\n",
    "    df_online['signal'] = pd.to_numeric(df_online['signal'])\n",
    "    df_online = df_online[df_online.mac.isin(macs)].copy()\n",
    "\n",
    "    if agg:\n",
    "        df_online = df_online.groupby(['mac', 'xy-loc'])['signal'].agg(['mean']).reset_index()\n",
    "        df_online = pd.pivot_table(df_online, values='mean', columns='mac', index=['xy-loc'])\n",
    "    \n",
    "    if add_dummy:\n",
    "    ## add dummy angle\n",
    "        df_online['dummy_angle'] = df_online.apply(lambda x: sample(angles, 1)[0], axis=1)\n",
    "    return df_online\n",
    "    #df_online.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame\n",
    "\n",
    "#### Objective: Describe how you prepared the data.\n",
    "\n",
    "**df** : training set. Not aggregated by angle. **Will be aggregated by XY-loc and mac across orientation angles on demand as needed**\n",
    "\n",
    "**df_online** : testing set. Aggregated at outset, not touched until after cross validation.\n",
    "\n",
    "***mac addresses with fewer than 1,018,838 entries have been removed***\n",
    "\n",
    "***All angles have been shifted to the nearest 45 degree interval (i.e all angles have been mapped to [0,45...135,180,..315,360]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data(f_offline)\n",
    "df_online = get_data(f_online, add_dummy=True, agg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1018838 entries, 0 to 1181626\n",
      "Data columns (total 12 columns):\n",
      "time                  1018838 non-null object\n",
      "scanMac               1018838 non-null object\n",
      "posX                  1018838 non-null object\n",
      "posY                  1018838 non-null object\n",
      "posZ                  1018838 non-null object\n",
      "orientation           1018838 non-null float64\n",
      "mac                   1018838 non-null object\n",
      "signal                1018838 non-null int64\n",
      "channel               1018838 non-null object\n",
      "type                  1018838 non-null object\n",
      "mapped_orientation    1018838 non-null int64\n",
      "xy-loc                1018838 non-null object\n",
      "dtypes: float64(1), int64(2), object(9)\n",
      "memory usage: 101.1+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>scanMac</th>\n",
       "      <th>posX</th>\n",
       "      <th>posY</th>\n",
       "      <th>posZ</th>\n",
       "      <th>orientation</th>\n",
       "      <th>mac</th>\n",
       "      <th>signal</th>\n",
       "      <th>channel</th>\n",
       "      <th>type</th>\n",
       "      <th>mapped_orientation</th>\n",
       "      <th>xy-loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1139643118358</td>\n",
       "      <td>00:02:2D:21:0F:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:14:bf:b1:97:8a</td>\n",
       "      <td>-38</td>\n",
       "      <td>2437000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1139643118358</td>\n",
       "      <td>00:02:2D:21:0F:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:14:bf:b1:97:90</td>\n",
       "      <td>-56</td>\n",
       "      <td>2427000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139643118358</td>\n",
       "      <td>00:02:2D:21:0F:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:0f:a3:39:e1:c0</td>\n",
       "      <td>-53</td>\n",
       "      <td>2462000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1139643118358</td>\n",
       "      <td>00:02:2D:21:0F:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:14:bf:b1:97:8d</td>\n",
       "      <td>-65</td>\n",
       "      <td>2442000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1139643118358</td>\n",
       "      <td>00:02:2D:21:0F:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:14:bf:b1:97:81</td>\n",
       "      <td>-65</td>\n",
       "      <td>2422000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time            scanMac posX posY posZ  orientation  \\\n",
       "0  1139643118358  00:02:2D:21:0F:33  0.0  0.0  0.0          0.0   \n",
       "1  1139643118358  00:02:2D:21:0F:33  0.0  0.0  0.0          0.0   \n",
       "2  1139643118358  00:02:2D:21:0F:33  0.0  0.0  0.0          0.0   \n",
       "3  1139643118358  00:02:2D:21:0F:33  0.0  0.0  0.0          0.0   \n",
       "4  1139643118358  00:02:2D:21:0F:33  0.0  0.0  0.0          0.0   \n",
       "\n",
       "                 mac  signal     channel type  mapped_orientation   xy-loc  \n",
       "0  00:14:bf:b1:97:8a     -38  2437000000    3                   0  0.0-0.0  \n",
       "1  00:14:bf:b1:97:90     -56  2427000000    3                   0  0.0-0.0  \n",
       "2  00:0f:a3:39:e1:c0     -53  2462000000    3                   0  0.0-0.0  \n",
       "3  00:14:bf:b1:97:8d     -65  2442000000    3                   0  0.0-0.0  \n",
       "4  00:14:bf:b1:97:81     -65  2422000000    3                   0  0.0-0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  45  90 135 180 225 270 315 360]\n",
      "[360 135  90 270   0 180 315  45 225]\n"
     ]
    }
   ],
   "source": [
    "print(df.mapped_orientation.unique())\n",
    "#note that DF online has been aggregated across its mapped orientations in the get_data method above\n",
    "#the dummy angle serves as an input in the modeling/prediction process below\n",
    "print(df_online.dummy_angle.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 60 entries, 0.0-0.05 to 9.86-3.88\n",
      "Data columns (total 9 columns):\n",
      "00:0f:a3:39:dd:cd    60 non-null float64\n",
      "00:0f:a3:39:e1:c0    60 non-null float64\n",
      "00:14:bf:3b:c7:c6    60 non-null float64\n",
      "00:14:bf:b1:97:81    60 non-null float64\n",
      "00:14:bf:b1:97:8a    60 non-null float64\n",
      "00:14:bf:b1:97:8d    60 non-null float64\n",
      "00:14:bf:b1:97:90    60 non-null float64\n",
      "02:00:42:55:31:00    60 non-null float64\n",
      "dummy_angle          60 non-null int64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 4.7+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>mac</th>\n",
       "      <th>00:0f:a3:39:dd:cd</th>\n",
       "      <th>00:0f:a3:39:e1:c0</th>\n",
       "      <th>00:14:bf:3b:c7:c6</th>\n",
       "      <th>00:14:bf:b1:97:81</th>\n",
       "      <th>00:14:bf:b1:97:8a</th>\n",
       "      <th>00:14:bf:b1:97:8d</th>\n",
       "      <th>00:14:bf:b1:97:90</th>\n",
       "      <th>02:00:42:55:31:00</th>\n",
       "      <th>dummy_angle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xy-loc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0-0.05</th>\n",
       "      <td>-63.207207</td>\n",
       "      <td>-52.227273</td>\n",
       "      <td>-62.948980</td>\n",
       "      <td>-61.813953</td>\n",
       "      <td>-40.068966</td>\n",
       "      <td>-63.043011</td>\n",
       "      <td>-55.233333</td>\n",
       "      <td>-86.369863</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15-9.42</th>\n",
       "      <td>-66.117117</td>\n",
       "      <td>-55.275229</td>\n",
       "      <td>-73.961905</td>\n",
       "      <td>-72.701031</td>\n",
       "      <td>-47.813084</td>\n",
       "      <td>-69.454545</td>\n",
       "      <td>-46.880000</td>\n",
       "      <td>-88.712766</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.31-11.09</th>\n",
       "      <td>-67.054054</td>\n",
       "      <td>-51.709091</td>\n",
       "      <td>-70.082474</td>\n",
       "      <td>-70.098901</td>\n",
       "      <td>-54.088235</td>\n",
       "      <td>-69.131579</td>\n",
       "      <td>-53.886598</td>\n",
       "      <td>-86.985507</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.47-8.2</th>\n",
       "      <td>-74.153153</td>\n",
       "      <td>-49.500000</td>\n",
       "      <td>-64.258065</td>\n",
       "      <td>-72.597701</td>\n",
       "      <td>-45.652893</td>\n",
       "      <td>-60.797468</td>\n",
       "      <td>-49.580000</td>\n",
       "      <td>-85.341463</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.78-10.94</th>\n",
       "      <td>-71.403670</td>\n",
       "      <td>-53.263636</td>\n",
       "      <td>-66.960000</td>\n",
       "      <td>-66.809524</td>\n",
       "      <td>-48.413793</td>\n",
       "      <td>-65.000000</td>\n",
       "      <td>-54.846939</td>\n",
       "      <td>-88.032258</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "mac         00:0f:a3:39:dd:cd  00:0f:a3:39:e1:c0  00:14:bf:3b:c7:c6  \\\n",
       "xy-loc                                                                \n",
       "0.0-0.05           -63.207207         -52.227273         -62.948980   \n",
       "0.15-9.42          -66.117117         -55.275229         -73.961905   \n",
       "0.31-11.09         -67.054054         -51.709091         -70.082474   \n",
       "0.47-8.2           -74.153153         -49.500000         -64.258065   \n",
       "0.78-10.94         -71.403670         -53.263636         -66.960000   \n",
       "\n",
       "mac         00:14:bf:b1:97:81  00:14:bf:b1:97:8a  00:14:bf:b1:97:8d  \\\n",
       "xy-loc                                                                \n",
       "0.0-0.05           -61.813953         -40.068966         -63.043011   \n",
       "0.15-9.42          -72.701031         -47.813084         -69.454545   \n",
       "0.31-11.09         -70.098901         -54.088235         -69.131579   \n",
       "0.47-8.2           -72.597701         -45.652893         -60.797468   \n",
       "0.78-10.94         -66.809524         -48.413793         -65.000000   \n",
       "\n",
       "mac         00:14:bf:b1:97:90  02:00:42:55:31:00  dummy_angle  \n",
       "xy-loc                                                         \n",
       "0.0-0.05           -55.233333         -86.369863          360  \n",
       "0.15-9.42          -46.880000         -88.712766          135  \n",
       "0.31-11.09         -53.886598         -86.985507          360  \n",
       "0.47-8.2           -49.580000         -85.341463           90  \n",
       "0.78-10.94         -54.846939         -88.032258           90  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_online.info())\n",
    "df_online.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Online Test Set Should Flatten out to 60 rows per textbook example***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_online.shape[0] == 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "00:0f:a3:39:e1:c0    145862\n",
       "00:0f:a3:39:dd:cd    145619\n",
       "00:14:bf:b1:97:8a    132962\n",
       "00:14:bf:3b:c7:c6    126529\n",
       "00:14:bf:b1:97:90    122315\n",
       "00:14:bf:b1:97:8d    121325\n",
       "00:14:bf:b1:97:81    120339\n",
       "02:00:42:55:31:00    103887\n",
       "Name: mac, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mac'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Measurements and Error\n",
    "\n",
    "#### Objective: Describe how you estimated your error and found the best fit ASSUMING you CANNOT USE THE ONLINE DATA.\n",
    "\n",
    "Distance between two points in space will be defined as the **euclidean** distance between the point we wish to classify and the collection of points in our sample **signal space** (a n-dimensional space consisting of each mac address' signal reading).\n",
    "\n",
    "$$d_{signal space}=\\sqrt{\\sum_{i=1}^{i=n}{({S_{i}-{T}_{i}})^2}}$$\n",
    "\n",
    "Error will similarly be evaluated, but in the more traditional euclidean distance represented in 2-d space (i.e the **pythagorean theorem**). Using this as a metric for scoring (lower is better) will allow us to distinguish the best algorithm parameters. \n",
    "\n",
    "$$Error_{prediction}=\\sqrt{({X_{target}-{X}_{predicted}})^2 + ({Y_{target}-{Y}_{predicted}})^2}$$\n",
    "\n",
    "Additionally, we will use an inverse distance weighting to weight our XY predictions in our nearest neighbor algorithm to see if we can smooth out the effect of increasing values of k.\n",
    "\n",
    "$$Weight_{i}=\\frac{1/d_{i}}{\\sum_{j=1}^{j=k}{1/d_{j}}}$$\n",
    "\n",
    "***Due to the fact that we cannot build our model with knowledge of the online dataset, we will use a train/test split and cross validation to select the best model for locating the OFFLINE set***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split\n",
    "\n",
    "**Optimal k** - we'll search for the optimal value of k (the number of neighbors to be included in making our prediction) by performing a **5 fold cross validation** on a range of **ks from 2-20**. Each fold will consist of an **80/20 train/test split** for the entire offline dataset. 80% will be used to form our nearest neighbor graph which will then be used to estimate the X-Y location of the remaining 20% of points. \n",
    "\n",
    "The parameter m will be set to **three** for this particular selection of k. Setting m to 3 will run this cross val using a sample from 3 angle orientations that bracket the dummy angle provided in the validation/testing sets (**which are randomly assigned**). If an angle of 45 is passed into the filter, the training set will consist of angles in [0, 45, 90]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_val_results = []\n",
    "#not checking angle balance here is a problem -  note in summary\n",
    "for fold in range(1, 6): #5 folds\n",
    "    all_indices = set(df.index)\n",
    "    keep = int(round(len(all_indices)*0.8, 0))\n",
    "    train_labels = set(sample(all_indices, keep))\n",
    "    test_labels = all_indices.difference(train_labels)\n",
    "    train_data = df.loc[train_labels]\n",
    "    test_data = df.loc[test_labels]\n",
    "    test_data = test_data.groupby(['mac', 'xy-loc'])['signal'].agg(['mean']).reset_index()\n",
    "    test_data = pd.pivot_table(test_data, values='mean', columns='mac', index=['xy-loc'])\n",
    "    test_data['dummy_angle'] = test_data.apply(lambda x: sample(angles, 1)[0], axis=1)\n",
    "    cv = cross_validate(train_data, test_data, ks=range(2, 20), m=3)\n",
    "    cv['fold'] = fold\n",
    "    cross_val_results.append(cv)\n",
    "    print(f'Fold: {fold} completed')\n",
    "    \n",
    "cross_val_results = pd.concat(cross_val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for k, predictions in cross_val_results.groupby(['k']):\n",
    "    scored = score(predictions)\n",
    "    error = scored.error.sum()\n",
    "    error_weighted = scored.error_weighted.sum()\n",
    "    results.append({\n",
    "        'k':k,\n",
    "        'error':error,\n",
    "        'error_weighted':error_weighted\n",
    "    })\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "p = sns.lineplot(data=results, x='k', y='error', label='error')\n",
    "sns.lineplot(data=results, x='k', y='error_weighted', label='weighted_error')\n",
    "p.set(title=f'Error vs k', ylabel='error')\n",
    "#    print(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Val Results\n",
    "\n",
    "#### Objective: Describe the best fit for the data.\n",
    "\n",
    "As expected, the weighted predictions generally performed better, having lower values for error across the board. Unfortunately, it's difficult to assess where the elbow is on the chart and **it seems to be counterintuitive that the errors increase almost monotonically with increasing k**. Since there appears to be bump at around 3 or 4, we'll try that as a value. Anything lower than that seems too small. We will continue our fitting process below by swapping out a few of the mac addresses that may not be reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cD or c0?\n",
    "\n",
    "#### Objective: There are 2 macIDs located at the same position.  Does one give better performance than the other?\n",
    "\n",
    "It has been suggested that one of these two devices may be faulty or that they may be less useful when used in tandem. Let's see if our modeling improves if we leave one of the devices in and the other out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macs_no_c0 = ['00:0f:a3:39:dd:cd', \n",
    "            '00:14:bf:b1:97:8a',\n",
    "            '00:14:bf:3b:c7:c6',    \n",
    "            '00:14:bf:b1:97:90',  \n",
    "            '00:14:bf:b1:97:8d',\n",
    "            '00:14:bf:b1:97:81',\n",
    "            '02:00:42:55:31:00']\n",
    "macs_no_cd = ['00:0f:a3:39:e1:c0',     \n",
    "            '00:14:bf:b1:97:8a',\n",
    "            '00:14:bf:3b:c7:c6',    \n",
    "            '00:14:bf:b1:97:90',  \n",
    "            '00:14:bf:b1:97:8d',\n",
    "            '00:14:bf:b1:97:81',\n",
    "            '02:00:42:55:31:00']\n",
    "\n",
    "df_no_c0 = get_data(f_offline, macs=macs_no_c0)\n",
    "df_online_no_c0 = get_data(f_online,macs=macs_no_c0, add_dummy=True, agg=True)\n",
    "df_no_cd = get_data(f_offline, macs=macs_no_cd)\n",
    "df_online_no_cd = get_data(f_online,macs=macs_no_cd, add_dummy=True, agg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No C0\n",
    "\n",
    "***Limiting k search space to 7 and foregoing CV to keep run time low***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = set(df_no_c0.index)\n",
    "keep = int(round(len(all_indices)*0.8, 0))\n",
    "train_labels = set(sample(all_indices, keep))\n",
    "test_labels = all_indices.difference(train_labels)\n",
    "train_data = df_no_c0.loc[train_labels]\n",
    "test_data = df_no_c0.loc[test_labels]\n",
    "test_data = test_data.groupby(['mac', 'xy-loc'])['signal'].agg(['mean']).reset_index()\n",
    "test_data = pd.pivot_table(test_data, values='mean', columns='mac', index=['xy-loc'])\n",
    "test_data['dummy_angle'] = test_data.apply(lambda x: sample(angles, 1)[0], axis=1)\n",
    "results_c0 = cross_validate(train_data, test_data, ks=range(2, 7), m=3, macs=macs_no_c0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for k, predictions in results_c0.groupby(['k']):\n",
    "    scored = score(predictions)\n",
    "    error = scored.error.sum()\n",
    "    error_weighted = scored.error_weighted.sum()\n",
    "    results.append({\n",
    "        'k':k,\n",
    "        'error':error,\n",
    "        'error_weighted':error_weighted\n",
    "    })\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "p = sns.lineplot(data=results, x='k', y='error', label='error')\n",
    "sns.lineplot(data=results, x='k', y='error_weighted', label='weighted_error')\n",
    "p.set(title=f'Error vs k w/o C0', ylabel='error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elbow plot shows a turn right around the k = 3 mark. Again, weighted error was lower across the search space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No CD\n",
    "\n",
    "***Limiting k search space to 7 and foregoing CV to keep run time low***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = set(df_no_cd.index)\n",
    "keep = int(round(len(all_indices)*0.8, 0))\n",
    "train_labels = set(sample(all_indices, keep))\n",
    "test_labels = all_indices.difference(train_labels)\n",
    "train_data = df_no_cd.loc[train_labels]\n",
    "test_data = df_no_cd.loc[test_labels]\n",
    "test_data = test_data.groupby(['mac', 'xy-loc'])['signal'].agg(['mean']).reset_index()\n",
    "test_data = pd.pivot_table(test_data, values='mean', columns='mac', index=['xy-loc'])\n",
    "test_data['dummy_angle'] = test_data.apply(lambda x: sample(angles, 1)[0], axis=1)\n",
    "results_cd = cross_validate(train_data, test_data, ks=range(2, 7), m=3, macs=macs_no_cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for k, predictions in results_cd.groupby(['k']):\n",
    "    scored = score(predictions)\n",
    "    error = scored.error.sum()\n",
    "    error_weighted = scored.error_weighted.sum()\n",
    "    results.append({\n",
    "        'k':k,\n",
    "        'error':error,\n",
    "        'error_weighted':error_weighted\n",
    "    })\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "p = sns.lineplot(data=results, x='k', y='error', label='error')\n",
    "sns.lineplot(data=results, x='k', y='error_weighted', label='weighted_error')\n",
    "p.set(title=f'Error vs k w/o CD', ylabel='error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elbow plot shows a turn right around the k = 3 mark. Again, weighted error was lower across the search space.\n",
    "\n",
    "#### Objective: What about using them both?\n",
    "\n",
    "Overall, predicting with one or the other seems better than predicting with both though there was not much of a difference in the best error rate achieved by leaving one out instead of the other. *Error rates for both methods at the optimal k of 3 were nearly identical*.\n",
    "\n",
    "**In our final analysis we will use the data without CD and with k=3.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Predictions\n",
    "\n",
    "Using the optimal values of k selected in cross validation, we will make predictions on the **online** testing set using the same methodology outlined above. We'll search a bit outside our targeted value of k to see if errors improve or worsen as k changes. Ideally, our choice of k should be an elbow point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_model_predictions = cross_validate(df_no_cd, df_online_no_cd, ks=[2, 3, 4], m=3, macs=macs_no_cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for key, predictions in final_model_predictions.groupby(['k']):\n",
    "    scored = score(predictions)\n",
    "    error = scored.error.sum()\n",
    "    error_weighted = scored.error_weighted.sum()\n",
    "    results.append({\n",
    "        'k':key,\n",
    "        'error':error,\n",
    "        'error_weighted':error_weighted\n",
    "    })\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "p = sns.lineplot(data=results, x='k', y='error', color='red', label='error')\n",
    "sns.lineplot(data=results, x='k', y='error_weighted', color='blue', label='weighted')\n",
    "p.set(title='Error vs k (online)', ylabel='error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions/Final Analysis\n",
    "\n",
    "\n",
    "#### Objective: What is the drawback (if any of using this method to real-time locate an object)?\n",
    "\n",
    "- The main drawback of using this method is speed and in order to account for that we have traded off a great deal of accuracy by aggregating with respect to angle of orientation. While the speed boost was necessary, it still was not enough to make this a viable real time locations tracking system. **Using the dummy angle as decribed in the book is also rather dubious, given more time we would've like to make the testing set larger by disaggregaton and then cross reference that with a more robust training set**.\n",
    "\n",
    "- The angles didn't seem like useful data to use in this method because the device will always be held in multiple angles based on the user preference inside the warehouse. Whether the user is holding the device up, down or to the side, the main objective is toidentify the actual location of the device in real time. So as long as we can determine the actual location of the device, the angles are uneccessary.\n",
    "\n",
    "- The positioning of the actual receivers can also play a part because it is hard to determine if the device is located in multiple floors. Such as being in the 3rd floor because of a mezzanine inside the warehouse compared to being on floor level. It is possible the solution will provide you with the wrong location/distance.\n",
    "\n",
    "#### Objective: Describe a method that may be an improvement based on your perceived drawbacks.\n",
    "\n",
    "Various improvements could include:\n",
    "\n",
    "- using a different metric for distance such as **manhattan distance** could lead to different/improved results. Alternatively, we could have attempted to use a different weighting scheme rather than **distance**, perhaps **exponential smoothing** or some other type of decay methodology.\n",
    "\n",
    "- caching our training data in variety of angle sweeps so that it does't have to be created every time the algorithm is called. In theory, if we increased the size of the testing set by including an angle then we could use the cached data to quickly create a multitude of kNN graphs and select from those to create our final kNN graph. This would ultimately improve speed and accuracy.\n",
    "\n",
    "- Fully utilizing the heat mapping, using the median signal at two access points and two angles. The heat map nicely illustrates representation of signal stength. So you can see how people move around your venue. This allows you to gain important insights on whatâ€™s good about your layout."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
